# NLP2021_project

# 1 задача
Для дальнейшей работы с данными провели разметку BIO-tagging с помощью stanza.
Далее сделали классификатор с помощью предобученной модели rubert-tiny. 

Классификатор был обучен на размечнных данных, выставили следующие параметры:

- optimizer Adam
- learning rate 5e-5
- 3 эпохи
- batch_size 8

Предобработка не использовалась ввиду отсутствия ее необходимости для BERTа.


# 2 задача

# 3 задача
Определить тональность каждого аспекта для отзыва в целом, зная оценки тональности для словосочетаний, относящихся к аспектам.
Бейзлайн: для каждого аспекта - ответ самая частая тональность.
Звучит логично, давайте подумаем, что еще можно придумать. Например, сразу брать в ответ тональность первого словосочетания. Вторая версия -  обозначить тональности за -1, +1 и 0, и посчитать сумму (score). Третья версия - то же, что вторая, но тональность первого словосочетания брать с весом два, рассчитывая, что в начале говорится наиболее важная информация, а потом детали.

Бейзлайн на трейне - 0.716

Первая версия - 0.657

Вторая версия - 0.776

Третья версия - 0.781

Затем мы заметили, что в категории WHOLE всегда что-то есть, даже если не было ни одного аспекта, с упоминанием чего-то из WHOLE. Добавили условие, что если ни одного WHOLE нету, то whole считается из всех аспектов.
Третья версия+ - 0.786
Затем мы заметили, что есть еще тональность ‘both’, попытались добавить условие, что если score попадает в самый частый диапазон для ‘both’, и число позитивных и негативных словосочетаний тоже самое частотное для такой штуки, то будем присваивать аспекту тональность both. В итоге где-то с both мы угадали, но чаще налажали с тем, что раньше определяли верно, точность снизилась - 0.768.

Лучше всего подходит третья версия.
